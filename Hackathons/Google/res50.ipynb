{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Input, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam,SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../input/landmark-retrieval-2020/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(fn):\n",
    "    fn[0]\n",
    "    return \"../input/landmark-retrieval-2020/train/\"+fn[0]+\"/\"+fn[1]+\"/\"+fn[2]+\"/\"+fn+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"path\"]=df[\"id\"].apply(append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(df['landmark_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.groupby(\"landmark_id\").head(20).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=df.groupby(\"landmark_id\").count()['id']>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "for i in count.index:\n",
    "    if count[i]==True:\n",
    "        labels+=[i]\n",
    "df=df[df['landmark_id'].isin(labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=len(labels)) as pbar:\n",
    "    for i in range(len(labels)):\n",
    "        #df[df['landmark_id']==labels[i]]=\n",
    "        pbar.update(1)\n",
    "        df.loc[df['landmark_id']==labels[i], 'landmark_id'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(validation_split=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=None,\n",
    "    x_col=\"path\",\n",
    "    y_col=\"landmark_id\",\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(400,400),\n",
    "    batch_size=25,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    subset=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=None,\n",
    "    x_col=\"path\",\n",
    "    y_col=\"landmark_id\",\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(400,400),\n",
    "    batch_size=25,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.applications import VGG16, ResNet50, ResNet101, InceptionResNetV2, Xception\n",
    "from keras.applications.resnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg = ResNet50(input_shape=(400,400,3), weights='imagenet', include_top=False)\n",
    "#vgg.load_weights(\"../input/myresnet101/my_h5_model.h5\")\n",
    "\n",
    "#input_image = Input((400,400,3))\n",
    "#x = tf.cast(input_image, tf.float32)\n",
    "#x=preprocess_input(x)\n",
    "#x = vgg(x)\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "#x=Dropout(0.3)(x)\n",
    "#x=Dense(4096, activation='linear')(x)\n",
    "#x=Dropout(0.3)(x)\n",
    "\n",
    "#output=Dense(len(labels), activation=tf.nn.softmax)(x)\n",
    "\n",
    "#model = Model(inputs=[input_image], outputs=[output])\n",
    "model=tf.keras.models.load_model('../input/modelintermediate/modelsigmoid4.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer('resnet101').trainable=True\n",
    "#vgg.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layers in model.layers[:6]:\n",
    "#    layers.trainable=False\n",
    "#model.get_layer('dense_1').trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.7),\n",
    "             ModelCheckpoint(\"modelsigmoid5.h5\", save_best_only=True),\n",
    "             EarlyStopping(\"val_loss\", restore_best_weights = True, patience = 5)]\n",
    "#ckpt = ModelCheckpoint(\"model.h5\", save_best_only=True)\n",
    "#es = EarlyStopping(\"val_categorical_accuracy\", restore_best_weights = True, patience = 5)\n",
    "#rs = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(2.8391e-05),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator,\n",
    "          validation_data=valid_generator,\n",
    "          epochs=20,\n",
    "          steps_per_epoch=1000,\n",
    "          validation_steps=500,\n",
    "          max_queue_size=20,\n",
    "          workers=4,\n",
    "          shuffle=True,\n",
    "          #use_multiprocessing=True,\n",
    "          callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(0.0000001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_generator,\n",
    "          #validation_data=valid_generator,\n",
    "#          epochs=1,\n",
    "          #steps_per_epoch=1000,\n",
    "#          max_queue_size=20,\n",
    "#          workers=4,\n",
    "#          shuffle=True,\n",
    "          #use_multiprocessing=True,\n",
    "#          callbacks=callbacks\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer('inception_resnet_v2').trainable = False\n",
    "model= Model(inputs=model.input, outputs=model.get_layer('dense').output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None, None, 3], dtype=tf.uint8, name='input_image')\n",
    "    ])\n",
    "    def call(self, input_image):\n",
    "        output_tensors = {}\n",
    "        \n",
    "        # resizing\n",
    "        im = tf.image.resize(input_image, (400,400))\n",
    "        \n",
    "        # preprocessing\n",
    "        #im = preprocess_input(im)\n",
    "        \n",
    "        extracted_features = self.model(tf.convert_to_tensor([im], dtype=tf.uint8))[0]\n",
    "        output_tensors['global_descriptor'] = tf.identity(extracted_features, name='global_descriptor')\n",
    "        return output_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "served_function = m.call\n",
    "tf.saved_model.save(\n",
    "      m, export_dir=\"./my_model\", signatures={'serving_default': served_function})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "li=os.listdir('./my_model/variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('submission.zip','w') as zip:           \n",
    "    zip.write('./my_model/saved_model.pb', arcname='saved_model.pb') \n",
    "    for i in li:\n",
    "        zip.write('./my_model/variables/'+i, arcname='variables/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
